{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datasets.PupilCoreDatasetIfOpened import PupilCoreDatasetIfOpened\n",
    "from datasets.PupilCoreDatasetPupil import PupilCoreDatasetPupil\n",
    "from datasets.PupilCoreDatasetCornealReflection import PupilCoreDatasetCornealReflection\n",
    "from models.ifOpened import ifOpenedModel\n",
    "from models.pupilDetectModel import PupilDetectModel\n",
    "from models.utils import train_first_model\n",
    "import models.utils as utils\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import copy\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = PupilCoreDatasetIfOpened(\n",
    "#     \"datasets/PupilCoreDataset/video5_eye0_video.avi\",\n",
    "#     'datasets/PupilCoreDataset/video5_eye0_pupildata.csv',\n",
    "#     \"datasets/PupilCoreDataset/video5_eye1_video.avi\",\n",
    "#     'datasets/PupilCoreDataset/video5_eye1_pupildata.csv'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = torch.randperm(len(dataset)).tolist()\n",
    "# train_part = int(0.8 * len(dataset))\n",
    "# train_dataset = torch.utils.data.Subset(dataset, indices[:train_part])\n",
    "# test_dataset = torch.utils.data.Subset(dataset, indices[train_part:])\n",
    "# dataset_sizes = {\n",
    "#     'train': len(train_dataset),\n",
    "#     'test': len(test_dataset)\n",
    "# }\n",
    "\n",
    "# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "# test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "# dataloaders = {\n",
    "#     \"train\": train_dataloader,\n",
    "#     \"test\": test_dataloader\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ifOpenedModel()\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# model = train_first_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=2, dataloaders=dataloaders, dataset_sizes=dataset_sizes, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for datasetCoords.py\n",
    "model_pupil = models.resnet18(pretrained=False)\n",
    "model_pupil.fc = nn.Linear(in_features=512, out_features=2, dtype=torch.float32)\n",
    "# model_pupil = PupilDetectModel()\n",
    "\n",
    "model_pupil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pupil = PupilCoreDatasetPupil(\n",
    "    \"datasets/PupilCoreDataset/video5_eye0_video.avi\",\n",
    "    'datasets/PupilCoreDataset/video5_eye0_pupildata.csv',\n",
    "    \"datasets/PupilCoreDataset/video5_eye1_video.avi\",\n",
    "    'datasets/PupilCoreDataset/video5_eye1_pupildata.csv'\n",
    ")\n",
    "indices = torch.randperm(len(dataset_pupil)).tolist()\n",
    "train_part = int(0.8 * len(dataset_pupil))\n",
    "train_dataset = torch.utils.data.Subset(dataset_pupil, indices[:train_part])\n",
    "test_dataset = torch.utils.data.Subset(dataset_pupil, indices[train_part:])\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'test': len(test_dataset)\n",
    "}\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "dataloaders = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"test\": test_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_second_model(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs,\n",
    "    device,\n",
    "    dataloaders,\n",
    "    dataset_sizes,\n",
    "):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    model = model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"test\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.01\n",
    "            running_corrects = 0\n",
    "            losses = []\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    # print(outputs, labels)\n",
    "                    outputs.to(device)\n",
    "                    \n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                losses.append(loss.item())\n",
    "                # print(running_loss)\n",
    "\n",
    "                if i % 500 == 0:\n",
    "                    print(f\"{phase}, Batch: {i}/{len(dataloaders[phase])} Loss: {np.mean(losses):.4f}\")\n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            # epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            \n",
    "            # deep copy the model\n",
    "            # if phase == \"test\" and epoch_acc > best_acc:\n",
    "            #     best_acc = epoch_acc\n",
    "            #     best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model_pupil.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model_pupil = train_second_model(model_pupil, criterion, optimizer, exp_lr_scheduler, num_epochs=5, dataloaders=dataloaders, dataset_sizes=dataset_sizes, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(model, dataloader, device, num_images: int = 5):\n",
    "    model.eval()\n",
    "    fig = plt.figure()\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            center_out = list(map(int, outputs[0].cpu().numpy()))\n",
    "            center_labels = list(map(int, labels[0].cpu().numpy()))\n",
    "            print(f\"center_out: {center_out}\", f\"center_label: {center_labels}\")\n",
    "            image = np.transpose(inputs[0].cpu().numpy(), (1, 2, 0)).copy()\n",
    "            \n",
    "            # fig.add_subplot(1, num_images, i+1)\n",
    "            cv2.circle(image, center_out, 1, (255, 0, 0), 1)\n",
    "            cv2.circle(image, center_labels, 1, (0, 255, 0), 1)\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "            #cv2.imshow(\"xd\", image)\n",
    "            if i >= num_images:\n",
    "                \n",
    "                return\n",
    "\n",
    "                \n",
    "# visualize_pupil(model_pupil, dataloaders['test'], device, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloaders, device, dataset_sizes):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders[\"test\"]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            # print(outputs, labels)\n",
    "            diff = (labels[0][0] - outputs[0][0], labels[0][1] - outputs[0][1])\n",
    "            # print(diff)\n",
    "            dist = torch.sqrt(torch.pow(diff[0], 2) + torch.pow(diff[0], 2)) \n",
    "            if dist < 2: \n",
    "                correct += 1\n",
    "        \n",
    "        acc = correct / dataset_sizes['test']\n",
    "        print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model_pupil, dataloaders, device, dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_corneal = PupilCoreDatasetCornealReflection(\n",
    "    \"datasets/PupilCoreDataset/video5_eye0_video.avi\",\n",
    "    'datasets/PupilCoreDataset/video5_eye0_pupildata.csv',\n",
    "    \"datasets/PupilCoreDataset/video5_eye1_video.avi\",\n",
    "    'datasets/PupilCoreDataset/video5_eye1_pupildata.csv'\n",
    ")\n",
    "indices = torch.randperm(len(dataset_corneal)).tolist()\n",
    "train_part = int(0.8 * len(dataset_corneal))\n",
    "train_dataset = torch.utils.data.Subset(dataset_corneal, indices[:train_part])\n",
    "test_dataset = torch.utils.data.Subset(dataset_corneal, indices[train_part:])\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'test': len(test_dataset)\n",
    "}\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "dataloaders = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"test\": test_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO corneal reflection detec\n",
    "\n",
    "\n",
    "model_corneal = models.resnet18(pretrained=False)\n",
    "model_corneal.fc = nn.Linear(in_features=512, out_features=2, dtype=torch.float32)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model_corneal.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model_corneal = train_second_model(model_corneal, criterion, optimizer, exp_lr_scheduler, num_epochs=2, dataloaders=dataloaders, dataset_sizes=dataset_sizes, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model_corneal, dataloaders, device, dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(model_corneal, dataloaders[\"test\"] ,device, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 3 NN system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('my_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "835d31919e34e16ebfc56bd2c74fd77981e034dd4359f7c353db7e63b4248092"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
