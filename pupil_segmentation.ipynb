{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datasets.PupilCoreDatasetIfOpened import PupilCoreDatasetIfOpened\n",
    "from datasets.PupilCoreDatasetPupil import PupilCoreDatasetPupil\n",
    "import torch\n",
    "import time\n",
    "import copy\n",
    "from torchvision.models.segmentation import FCN_ResNet50_Weights, fcn_resnet50\n",
    "import numpy as np\n",
    "import cv2\n",
    "import utils\n",
    "from models.trainers import PupilSegmentationTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): FCNHead(\n",
       "    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = fcn_resnet50(weights=None, num_classes=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LEN_TO_USE = 5000\n",
    "dataset_pupil = PupilCoreDatasetPupil(\n",
    "    \"datasets/PupilCoreDataset/video5_eye0_video.avi\",\n",
    "    'datasets/PupilCoreDataset/video5_eye0_pupildata.csv',\n",
    "    \"datasets/PupilCoreDataset/video5_eye1_video.avi\",\n",
    "    'datasets/PupilCoreDataset/video5_eye1_pupildata.csv',\n",
    "    DATASET_LEN_TO_USE\n",
    ")\n",
    "# dataset_pupil.get_pupil_ellipse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_pupil.save_masks(\"datasets/PupilCoreDataset/created_masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x186ad109090>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_pupil.load_masks(\"datasets/PupilCoreDataset/created_masks/eye0\", \"datasets/PupilCoreDataset/created_masks/eye1\")\n",
    "torch.set_printoptions(edgeitems=100)\n",
    "\n",
    "plt.imshow(dataset_pupil.eye0_masks[0],cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pupil_trainer = PupilSegmentationTrainer(model=model, dataset=dataset_pupil, dataset_len=DATASET_LEN_TO_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"models/weights/resnet50.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(model, num_images: int = 5):\n",
    "    model.eval()\n",
    "    fig = plt.figure()\n",
    "    model = model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(Pupil_trainer.dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            image = np.transpose(inputs[0].cpu().numpy(), (1, 2, 0)).copy()\n",
    "            outputs_soft = torch.nn.functional.softmax(outputs['out'][0], dim=1)\n",
    "            outputs_sig = torch.sigmoid(outputs['out'][0])\n",
    "            outputs_sig = np.transpose(outputs_sig.cpu().numpy(), (1, 2, 0)).copy()\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "            # plt.imshow(outputs_soft)\n",
    "            # plt.show()\n",
    "            plt.imshow(outputs_sig)\n",
    "            plt.show()\n",
    "            \n",
    "            #cv2.imshow(\"xd\", image)\n",
    "            if i >= num_images:\n",
    "                \n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'outputs_sig' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m visualize(model, \u001b[39m5\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn [16], line 13\u001b[0m, in \u001b[0;36mvisualize\u001b[1;34m(model, num_images)\u001b[0m\n\u001b[0;32m     11\u001b[0m image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtranspose(inputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy(), (\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m))\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     12\u001b[0m outputs_soft \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(outputs[\u001b[39m'\u001b[39m\u001b[39mout\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m outputs_sig \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtranspose(outputs_sig\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy(), (\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m))\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     14\u001b[0m outputs_sig \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(outputs[\u001b[39m'\u001b[39m\u001b[39mout\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m])\n\u001b[0;32m     18\u001b[0m plt\u001b[39m.\u001b[39mimshow(image)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'outputs_sig' referenced before assignment"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ellipse():\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(Pupil_trainer.dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "\n",
    "            image = np.transpose(inputs[0].cpu().numpy(), (1, 2, 0)).copy()\n",
    "            # outputs_soft = torch.nn.functional.softmax(outputs['out'][0], dim=1)\n",
    "            outputs_sig = torch.sigmoid(outputs['out'][0])\n",
    "\n",
    "            outputs_sig = np.transpose(outputs_sig.cpu().numpy(), (1, 2, 0)).copy()\n",
    "\n",
    "            ellipse = utils.fit_ellipse(outputs_sig)\n",
    "            utils.draw_ellipse(image, ellipse)\n",
    "\n",
    "            \n",
    "\n",
    "            if i >0 :\n",
    "                break\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m draw_ellipse()\n",
      "Cell \u001b[1;32mIn [12], line 3\u001b[0m, in \u001b[0;36mdraw_ellipse\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_ellipse\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m----> 3\u001b[0m         \u001b[39mfor\u001b[39;00m i, (inputs, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloaders[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m      4\u001b[0m             inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      5\u001b[0m             labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloaders' is not defined"
     ]
    }
   ],
   "source": [
    "draw_ellipse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('my_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "835d31919e34e16ebfc56bd2c74fd77981e034dd4359f7c353db7e63b4248092"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
